# azure-iot-location-monitoring\.github\workflows\GithubActionsFullDeploy.yml

name: Full IoT Solution Deployment

on:
  workflow_dispatch:   # Manual trigger from GitHub UI

# Change to this after debugging...
# on:
#   push:
#     branches: [ main ]

jobs:
  deploy-solution:
    runs-on: ubuntu-latest
    env:
      ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
      ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
      ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

      TF_VAR_github_client_id: ${{ secrets.AZURE_CLIENT_ID }}
      TF_VAR_github_client_secret: ${{ secrets.AZURE_CLIENT_SECRET }}
      TF_VAR_github_subscription_id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      TF_VAR_github_tenant_id: ${{ secrets.AZURE_TENANT_ID }}
      TF_VAR_grafana_admin_principal_id: ${{ secrets.AZURE_USER_OBJECT_ID }}   # Used for granting User RBAC for Grafana

    steps:
      # --- 1. Terraform Infrastructure Deployment ---
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Log in to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.8.x

      - name: Terraform Init
        id: init
        run: terraform init -upgrade
        working-directory: ./terraform

      # ... (your commented-out conditional import step) ...
      
      - name: Terraform Apply
        id: terraform_apply_step # This ID is for the 'outputs' step to read from
        run: terraform apply -auto-approve 
        working-directory: ./terraform
        env:
          ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

          TF_VAR_github_client_id: ${{ secrets.AZURE_CLIENT_ID }}
          TF_VAR_github_client_secret: ${{ secrets.AZURE_CLIENT_SECRET }}
          TF_VAR_github_subscription_id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          TF_VAR_github_tenant_id: ${{ secrets.AZURE_TENANT_ID }}
          TF_VAR_grafana_admin_principal_id: ${{ secrets.AZURE_USER_OBJECT_ID }}   # Used for granting User RBAC for Grafana

      # ... (your commented-out Terraform Apply with Lock Recovery step) ...

      # --- 2. Extract Outputs from Terraform ---
      - name: Get Terraform Outputs
        id: terraform_outputs # This step's ID is used to reference its outputs IN SUBSEQUENT STEPS
        run: |
          # Install jq if not already present (ubuntu-latest usually has it, but good to be explicit)
          sudo apt-get update && sudo apt-get install -y jq

          # Retrieve all Terraform outputs as a JSON string
          TERRAFORM_OUTPUTS=$(terraform output -json)
          
          # Debugging: Print raw Terraform outputs JSON for inspection
          echo "--- Debug One: Raw Terraform Outputs JSON ---"
          echo "$TERRAFORM_OUTPUTS" | jq .
          echo "--- End Debug One ---"

          # Extract each output value into a TEMPORARY SHELL VARIABLE
          # This variable is available ONLY within this 'run' script.
          # Use default empty string if jq finds no value to prevent errors.
          # AKS_KUBECFG_VALUE will hold the string with literal \n and \r sequences from Terraform output.
          IOT_SIMULATOR_DEVICE_NAME_VALUE=$(echo "$TERRAFORM_OUTPUTS" | jq -r '.iot_simulator_device_name.value // ""')
          AKS_KUBECFG_VALUE=$(echo "$TERRAFORM_OUTPUTS" | jq -r '.aks_kube_config.value // ""')
          ACR_LOGIN_SERVER_VALUE=$(echo "$TERRAFORM_OUTPUTS" | jq -r '.acr_login_server.value // ""')
          IOT_HUB_NAME_VALUE=$(echo "$TERFORM_OUTPUTS" | jq -r '.iot_hub_name.value // ""')
          RESOURCE_GROUP_NAME_VALUE=$(echo "$TERRAFORM_OUTPUTS" | jq -r '.resource_group_name.value // ""')

          # --- ADD THESE LINES TO EXTRACT DATABRICKS JOB ID AND WORKSPACE URL ---
          DATABRICKS_JOB_ID_VALUE=$(echo "$TERRAFORM_OUTPUTS" | jq -r '.databricks_job_id.value // ""')
          # Extract workspace URL and remove 'https://' for DATABRICKS_HOST
          DATABRICKS_WORKSPACE_HOST_VALUE=$(echo "$TERRAFORM_OUTPUTS" | jq -r '.databricks_workspace_url_output.value // ""' | sed 's|^https://||')
          # --- END ADDITION ---

          # Now, write these shell variables to GITHUB_OUTPUT.
          # These become available as steps.terraform_outputs.outputs.* in LATER steps.
          echo "IOT_SIMULATOR_DEVICE_NAME=$IOT_SIMULATOR_DEVICE_NAME_VALUE" >> "$GITHUB_OUTPUT"

          echo "AKS_KUBECFG<<EOF" >> "$GITHUB_OUTPUT"   # Adapt to kubecfg being multi-line
          echo "$AKS_KUBECFG_VALUE" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

          echo "ACR_LOGIN_SERVER=$ACR_LOGIN_SERVER_VALUE" >> "$GITHUB_OUTPUT"
          echo "IOT_HUB_NAME=$IOT_HUB_NAME_VALUE" >> "$GITHUB_OUTPUT"
          echo "RESOURCE_GROUP_NAME=$RESOURCE_GROUP_NAME_VALUE" >> "$GITHUB_OUTPUT"

          # --- ADD THESE LINES TO EXPOSE DATABRICKS OUTPUTS TO GITHUB_OUTPUT ---
          echo "databricks_job_id=$DATABRICKS_JOB_ID_VALUE" >> "$GITHUB_OUTPUT"
          echo "databricks_workspace_host=$DATABRICKS_WORKSPACE_HOST_VALUE" >> "$GITHUB_OUTPUT"
          # --- END ADDITION ---

          # Debugging: Print the TEMPORARY SHELL VARIABLES to confirm they hold values
          echo "--- Debug Two: Values of shell variables set in this step ---"
          echo "IOT_SIMULATOR_DEVICE_NAME_VALUE: '$IOT_SIMULATOR_DEVICE_NAME_VALUE'"
          echo "AKS_KUBECFG_VALUE: (Truncated for brevity, check raw JSON if needed)"
          echo "$AKS_KUBECFG_VALUE" | head -n 5 
          echo "ACR_LOGIN_SERVER_VALUE: '$ACR_LOGIN_SERVER_VALUE'"
          echo "IOT_HUB_NAME_VALUE: '$IOT_HUB_NAME_VALUE'"
          echo "RESOURCE_GROUP_NAME_VALUE: '$RESOURCE_GROUP_NAME_VALUE'"
          echo "DATABRICKS_JOB_ID_VALUE: '$DATABRICKS_JOB_ID_VALUE'" # Debug print
          echo "DATABRICKS_WORKSPACE_HOST_VALUE: '$DATABRICKS_WORKSPACE_HOST_VALUE'" # Debug print
          echo "--- End Debug Two ---"
        working-directory: ./terraform

      # --- 3. Build & Deploy IoT Simulator to AKS ---
      # ... (your existing Docker build, push, AKS deployment steps) ...

      # --- 4. Trigger Databricks Job ---
      - name: Install Databricks CLI
        run: |
          pip install databricks-cli
          # Optional: Upgrade to the new CLI if desired, but current one works for now
          # pip install databricks-cli --upgrade # This installs the old CLI and upgrades it
          # pip install databricks-cli --upgrade --pre # To get the new CLI (v0.2xx.x or v0.3xx.x)
          # Then you'd use 'databricks-cli' or 'databricks' depending on the install

      - name: Trigger Databricks Job
        env:
          # Use the outputs from the 'terraform_outputs' step
          DATABRICKS_HOST: ${{ steps.terraform_outputs.outputs.databricks_workspace_host }} # Renamed output for clarity
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_PAT_TOKEN }}
        run: |
          echo "Attempting to trigger Databricks job..."
          databricks jobs run-now --job-id ${{ steps.terraform_outputs.outputs.databricks_job_id }}
          echo "Databricks job trigger command executed."

      # Optional: Add a step to monitor the job run status if you want to wait/fail
      # - name: Monitor Databricks Job Run
      #   run: |
      #     # ... (monitoring logic using databricks jobs get-run) ...