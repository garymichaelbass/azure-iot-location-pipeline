# Configure the connection and write details for Azure Cosmos DB.
cosmos_config = {
    "spark.cosmos.accountEndpoint": cosmos_db_endpoint, # Corrected key
    "spark.cosmos.accountKey": cosmos_db_key,           # Corrected key
    "spark.cosmos.database": cosmos_db_database,         # Corrected key
    "spark.cosmos.container": cosmos_db_container,       # Corrected key
    "spark.cosmos.upsert": "true"                        # Corrected key
    # You can also add "spark.cosmos.write.strategy": "ItemOverwrite" for upsert
}

print("ðŸ’¾ Preparing to write to Cosmos DB...")
print("Cosmos config keys:", list(cosmos_config.keys()))

logging.info(f"Cosmos DB configuration loaded for database: {cosmos_config['spark.cosmos.database']}, container: {cosmos_config['spark.cosmos.container']}")

# Write the processed streaming data from `json_df` to Azure Cosmos DB.
json_df.writeStream \
    .format("cosmos.oltp") \
    .options(**cosmos_config) \
    .outputMode("append") \
    .start()